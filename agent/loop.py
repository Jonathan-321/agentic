import json
import os
import re
import time
import uuid
from typing import Dict, Tuple, Any, List

from tools.builtin import BaseTool, get_builtin_tools
from agent.logger import JSONLLogger
from memory.memory import MemoryManager
from memory.summary import summarize_text
from memory.vector_store import VectorStore
from agent.context import ContextManager


class ReActAgent:
    def __init__(
        self,
        tools: Dict[str, BaseTool],
        logger: JSONLLogger,
        memory: MemoryManager,
        max_steps: int = 8,
        context_window_words: int = 1200,
        memory_mode: str = "none",  # none | summary | retrieval | both
    ):
        self.tools = tools
        self.logger = logger
        self.memory = memory
        self.max_steps = max_steps
        self.context_window_words = context_window_words
        self.memory_mode = memory_mode
        self.ctx_mgr = ContextManager(max_words=context_window_words)

    def run_task(self, task: Dict[str, Any], run_id: str) -> Tuple[str, Dict[str, Any]]:
        task_id = task.get("id") or str(uuid.uuid4())
        task_type = task.get("type")
        if task_type == "needle":
            return self._run_needle(task, run_id, task_id)
        if task_type == "long_horizon":
            return self._run_long_horizon(task, run_id, task_id)
        raise ValueError(f"Unknown task type: {task_type}")

    # Needle-in-haystack retrieval
    def _run_needle(self, task: Dict[str, Any], run_id: str, task_id: str) -> Tuple[str, Dict[str, Any]]:
        step = 0
        doc_path = task["doc_path"]
        key = task["key"]
        thought = "Need to scan the document and extract the hidden value for the given key."
        self.logger.log_step(run_id, task_id, step, thought, action="observe", tool=None, tool_input=None, observation=None)

        # Step 1: read file
        step += 1
        raw_doc = self.tools["read_file"].run(path=doc_path).output
        observation = raw_doc
        if self.context_window_words:
            words = raw_doc.split()
            observation = " ".join(words[: self.context_window_words])
        self.logger.log_step(
            run_id,
            task_id,
            step,
            thought="Read document",
            action="tool",
            tool="read_file",
            tool_input={"path": doc_path},
            observation=observation[:500],
        )
        self.ctx_mgr.add("doc", observation)

        # Step 2: search for key
        step += 1
        search_text = observation
        if self.memory_mode in {"summary", "both"}:
            summary = summarize_text(raw_doc, max_words=120, prefer_keyword="NEEDLE")
            self.tools["append_note"].run(note=f"doc_summary: {summary}", session="needle")
            search_text = summary
        if self.memory_mode in {"retrieval", "both"}:
            # chunk document and index
            chunk_words = raw_doc.split()
            chunk_size = 300
            for i in range(0, len(chunk_words), chunk_size):
                chunk = " ".join(chunk_words[i : i + chunk_size])
                self.tools["append_note"].run(note=f"doc_chunk: {chunk}", session="needle")
            retrieved = self.tools["search_memory"].run(query=key, session="needle", top_k=3).output
            search_text = retrieved or search_text

        value = self._extract_needle(search_text, key)
        if value is None:
            # maybe file large; re-read full content via data if truncated
            full_content = observation
            value = self._extract_needle(full_content, key)
        observation2 = f"found value={value}" if value is not None else "value not found"
        self.logger.log_step(run_id, task_id, step, thought="Parse for needle", action="analysis", tool=None, tool_input=None, observation=observation2)

        # Step 3: final
        step += 1
        answer = value or "not found"
        self.logger.log_step(run_id, task_id, step, thought="Return answer", action="final", tool=None, tool_input=None, observation=answer, decision=answer)
        return answer, {"steps": step}

    def _extract_needle(self, text: str, key: str) -> str | None:
        if not text:
            return None
        pattern = re.compile(rf"NEEDLE\s*:\s*{re.escape(key)}\s*->\s*([^\s]+)")
        m = pattern.search(text)
        if m:
            return m.group(1).strip().strip(".,;:!?")
        pattern2 = re.compile(rf"{re.escape(key)}\s*:\s*(\S+)")
        m2 = pattern2.search(text)
        if m2:
            return m2.group(1).strip().strip(".,;:!?")
        return None

    # Long-horizon instruction following
    def _run_long_horizon(self, task: Dict[str, Any], run_id: str, task_id: str) -> Tuple[str, Dict[str, Any]]:
        step = 0
        instructions = task["instructions"]
        recipe = task["recipe"]  # structured plan generated by eval

        thought = "Review constraints and plan computation."
        self.logger.log_step(run_id, task_id, step, thought, action="analyze", tool=None, tool_input=None, observation=instructions)

        # Step 1: optionally consult memory
        if self.memory_mode in {"retrieval", "both", "summary"}:
            step += 1
            mem_obs = self.tools["search_memory"].run(query=task.get("topic", "long_task"), session="long_horizon").output
            self.logger.log_step(run_id, task_id, step, thought="Consult episodic memory", action="tool", tool="search_memory", tool_input={"query": task.get("topic", "long_task")}, observation=mem_obs)

        # Step 2: execute recipe using python tool for transparency
        code_lines = ["import json", "result = {}"]
        banned = recipe.get("banned_word")

        # compute fields
        for field, spec in recipe.get("fields", {}).items():
            if spec["op"] == "concat":
                args = spec["args"]
                code_lines.append(f"result['{field}'] = '-'.join({args!r})")
            elif spec["op"] == "count_vowels":
                arg = spec["args"][0]
                code_lines.append("import re")
                code_lines.append(f"result['{field}'] = len(re.findall(r'[aeiou]', '{arg}', re.IGNORECASE))")
            elif spec["op"] == "reverse":
                arg = spec["args"][0]
                code_lines.append(f"result['{field}'] = '{arg}'[::-1]")
            elif spec["op"] == "uppercase":
                arg = spec["args"][0]
                code_lines.append(f"result['{field}'] = '{arg}'.upper()")
            else:
                code_lines.append(f"result['{field}'] = '{spec}'")
        code_lines.append("output = json.dumps(result, sort_keys=True)")
        python_code = "\n".join(code_lines)

        step += 1
        res = self.tools["python_exec"].run(code=python_code)
        observation = res.output
        self.logger.log_step(run_id, task_id, step, thought="Compute structured answer", action="tool", tool="python_exec", tool_input={"code": python_code}, observation=observation)

        # Build JSON from result data if present
        result_obj = res.data or {}
        final_text = json.dumps(result_obj, sort_keys=True)
        if banned and banned.lower() in final_text.lower():
            final_text = final_text.replace(banned, "[redacted]")

        step += 1
        self.logger.log_step(run_id, task_id, step, thought="Return JSON per constraints", action="final", tool=None, tool_input=None, observation=final_text, decision=final_text)

        # Persist a note when memory enabled
        if self.memory_mode in {"summary", "retrieval", "both"}:
            memo = f"Task {task_id} complete. Topic={task.get('topic','')}. Banned={banned}. Output={final_text}"
            self.tools["append_note"].run(note=memo, session="long_horizon")

        return final_text, {"steps": step}


# Convenience factory

def build_agent(log_path: str, use_memory: bool = False) -> ReActAgent:
    memory_dir = os.path.join("memory", "store")
    vector_store = VectorStore()
    tools = get_builtin_tools(memory_dir, vector_store=vector_store)
    logger = JSONLLogger(log_path)
    memory = MemoryManager(memory_dir)
    mode = "both" if use_memory else "none"
    return ReActAgent(tools=tools, logger=logger, memory=memory, memory_mode=mode)
